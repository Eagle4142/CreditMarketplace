---
title: "Assignment 1"
author: "David Krütli, Serhat Nergiz, Ibrahim Yaman, Mohamed Ramadan<br>"
date: "`r Sys.time()`"
output:
  github_document:
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Business Understanding

Text **to follow** here.

# Setup
## Load Required Packages

First of all we are going to load the packages required for this project.

```{r message = FALSE, warning = FALSE}
#install.packages("readr")
#install.packages("tidyverse")
<<<<<<< HEAD
#install.packages("formattable")
library(car)
library(corrplot)
library(dbplyr)
library(formattable)
library(Hmisc)
library(lmtest)
library(openxlsx)
library(readr)
library(tidyverse)

=======
library(readr)
library(tidyverse)
>>>>>>> 010c1ed15cec1a5361cbebc6d9e1496a987b081b
```


## Load Data

Next we are going to load the data from the CSV file "LCdata.csv" and display the first row to get a rough idea about the data.

```{r message = FALSE, warning = FALSE}
creditData <- read_delim("/Users/serhat/Downloads/LCdata.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
knitr::kable(head(creditData, 1))
```

## Data removal
The decision to drop certain variables from the dataset for predicting the interest rate of new loan applications is based on their unavailability or irrelevance at the time of prediction. First of all we are going to drop these variables:

```{r message = FALSE, warning = FALSE}
creditData2 <- subset(creditData,select=-c(collection_recovery_fee,
                                                       installment,
                                                       issue_d,
                                                       last_pymnt_amnt,
                                                       last_pymnt_d,
                                                       loan_status,
                                                       next_pymnt_d,
                                                       out_prncp,
                                                       out_prncp_inv,
                                                       pymnt_plan,
                                                       recoveries,
                                                       term,
                                                       total_pymnt,
                                                       total_pymnt_inv,
                                                       total_rec_int,
                                                       total_rec_late_fee,
                                                       total_rec_prncp))
```


Next we are removing all variables with more than 200'000 blank values.

```{r message = FALSE, warning = FALSE}
creditData2<- subset(creditData2,select=-c(annual_inc_joint,
                                                       desc,
                                                       dti_joint,
                                                       mths_since_last_delinq,
                                                       mths_since_last_major_derog,
                                                       mths_since_last_record,
                                                       open_acc_6m,
                                                       open_il_6m,
                                                       open_il_12m,
                                                       open_il_24m,
                                                       mths_since_rcnt_il,
                                                       total_bal_il,
                                                       il_util,
                                                       open_rv_12m,
                                                       open_rv_24m,
                                                       max_bal_bc,
                                                       all_util,
                                                       total_rev_hi_lim,
                                                       inq_fi,
                                                       total_cu_tl,
                                                       inq_last_12m))
```

We will also drop the variable url because with 798641 levels it is not going to say anything about our data. The policy code is also not really useful to predict the interest rate, because it only has the numeric value 1.

```{r message = FALSE, warning = FALSE}
creditData2<- subset(creditData2,select=-c(policy_code,
                                                       url))
```
# Explore Data

<<<<<<< HEAD
## Attribute revol_util

Display a summary of the attribute **revol_util**

```{r message = FALSE, warning = FALSE}
summary(creditData2$revol_util)
```

As we can see, this attribute has 454 blanks which we are going to remove entirely from the dataset.

```{r message = FALSE, warning = FALSE}
creditData2<- filter(creditData, ! is.na(revol_util))
creditData2$title <- tolower(creditData2$title)
```

## Attribute title
Display a summary of the attribute **revol_util**
```{r message = FALSE, warning = FALSE}
summary(creditData2$title)
```

It is visible, that we have 56143 levels and this is way to much. Let's see which of them are occuring the most.

```{r message = FALSE, warning = FALSE}

max(table(creditData2$title))
HäufigkeitTitle <- round(prop.table(table(creditData2title))*100,2)

tabelle <- cbind(HäufigkeitTitle)

kategorie_haeufigkeit <- table(creditData2$title)

sortierte_haeufigkeit <- sort(kategorie_haeufigkeit, decreasing = TRUE)

top30 <- head(sortierte_haeufigkeit, 30)

top30_namen <- names(top30)

creditData2$title <- ifelse(creditData2$title %in% top30_namen, creditData2$title, 'others')

table(creditData2$title)
creditData2$title <- factor("title")
```

We cann see that debt consolidation and credit card refinancing are dominating the categories with over 67% and many of the categories are redundant due to 
upper and lower cases. So we are making every value in lower cases and take the top 30 categories for the predicition.The rest will be sum up as "others"

## Attribute addr_state
=======
## Structure of the Dataset

```{r message = FALSE, warning = FALSE, echo=FALSE, results = 'asis'}
cat(paste0("The dataset has **", nrow(creditData), "** rows and **", ncol(creditData), "** columns."))
```

## Attributes

### Attribute addr_state
>>>>>>> 010c1ed15cec1a5361cbebc6d9e1496a987b081b

Display a summary of the attribute **addr_state**:

```{r message = FALSE, warning = FALSE}
summary(creditData$addr_state)
```

Plot the distribution of the attribute **addr_state**:

```{r message = FALSE, warning = FALSE}
plot(table(creditData$addr_state))
```

Build a contingency table of the counts at each combination of factor levels.

```{r message = FALSE, warning = FALSE}
table(creditData$addr_state)
```

**Conclusion**:

We should keep this attribute in the dataset for the moment. The interest rate could depend on the area where the borrower lives. This attribute needs to be converted into a categorical value (factor).

### Attribute annual_inc

Display a summary of the attribute **annual_inc**:

```{r message = FALSE, warning = FALSE}
summary(creditData$annual_inc)
```

Plot a historgram for **annual_inc**, where the annual income is higher than 500'000:

```{r message = FALSE, warning = FALSE}
hist((filter(creditData, annual_inc > 500000)$annual_inc), breaks = 1000)
```



As can be seen in the histogram, there are a few very high values, so we want to see if these are errors in our dataset. Therefore we are going to list the **emp_title** and **verification_status** for the top 50 values.

```{r message = FALSE, warning = FALSE}

select(head(creditData[order(creditData$annual_inc, decreasing = TRUE), ], 50), annual_inc, emp_title, verification_status)
```

Looks like there are indeed some unrealistic values in our dataset: A nurse with an annual income of USD 9.5 million or a commercial driver with USD 8.9 million seems to be way above the expected income, although source was verified.

**Conclusion**:

We should keep this attribute in the dataset for the moment. The interest rate would probably depend on the borrower's annual income, as this tells us something about the borrower's creditworthiness. The 4 records with NA for the annual income should be removed. We should also consider filling the values above a certain threshold (e.g. 800'000) with the median (i.e., 65'000).

### Attribute application_type

Display a summary of the attribute **application_type**:

```{r message = FALSE, warning = FALSE}
summary(creditData$application_type)
```

Plot the distribution of the attribute **application_type**:

```{r message = FALSE, warning = FALSE}
plot(table(creditData$application_type))
```

Build a contingency table of the counts at each combination of factor levels.

```{r message = FALSE, warning = FALSE}
table(creditData$application_type)
```

**Conclusion**:

The vast majority of applications are INDIVIDUAL (798181). Only 460 are JOINT. This attribute could be transformed in a binary value.


## Attribute verification_status

Display a summary of the attribute **verification_status**:

```{r message = FALSE, warning = FALSE}
count(creditData[is.na(creditData$verification_status), ])
class(creditData$verification_status)
```
Factorize the character value

```{r message = FALSE, warning = FALSE}
vec_Verif <- as.factor(creditData$verification_status)
class(vec_Verif)
```

## Attribute open_acc

Display the attribute open_acc
```{r message = FALSE, warning = FALSE}
summary(creditData$open_acc)
```

Display the class of the attribute open_acc:

```{r message = FALSE, warning = FALSE}
class(creditData$open_acc)
```
Assign the median value into the NAs

```{r message = FALSE, warning = FALSE}
med_open_acc <- median(creditData$open_acc, na.rm = TRUE)
med_open_acc
creditData[is.na(creditData$open_acc), "open_acc"] <- med_open_acc

```


## Attribute last_credit_pull_d

```{r message = FALSE, warning = FALSE}
unique(creditData$last_credit_pull_d)

```
Display the class

```{r message = FALSE, warning = FALSE}

class(creditData$last_credit_pull_d)
```
Factorize the attribute last_credit_pull_d

```{r message = FALSE, warning = FALSE}
vec_last_credit_pull_d <- as.factor(creditData$last_credit_pull_d)
class(vec_last_credit_pull_d)

```
Remove the blanks

```{r message = FALSE, warning = FALSE}
creditData <- creditData[!is.na(creditData$last_credit_pull_d), ]
creditData

```

## Attribute pub_rec

Assign the median into the missing values

```{r message = FALSE, warning = FALSE}
med_pub_rec <- median(creditData$pub_rec, na.rm = TRUE)
med_pub_rec
creditData[is.na(creditData$pub_rec), "pub_rec"] <- med_pub_rec

```
## Attribute purpose

Factorize the character
```{r message = FALSE, warning = FALSE}
vec_purpose <- as.factor(creditData$purpose)
class(vec_purpose)

```

### Attribute collections_12_mths_ex_med

### Attribute delinq_2yrs

### Attribute dti

### Attribute earliest_cr_line

### Attribute emp_length

### Attribute funded_amnt

### Attribute funded_amnt_inv

### Attribute home_ownership

### Attribute initial_list_status

### Attribute ...